<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>K8s</title><url>/post/k8s/</url><categories><category>学习</category></categories><tags><tag>技术</tag><tag>容器</tag><tag>docker</tag><tag>k8s</tag></tags><content type="html"> 容器篇 **## **进程
进程是分配资源的最小单元
容器技术的核心功能，就是通过约束资源和修改进程的动态表现，从而为其创造出一个边界。
Cgroups技术就是用来制造约束的主要手段** ****Namespace**技术则是用来修改进程视图的主要方法** ****rootfs**挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统
K8S 篇 k8s：按照用户的意愿和整个系统的规则，完全自动化的处理好容器之间的各种关系。也就是****编排，本质就是为用户提供一个具有普遍意义的容器编排工具
安装： 使用kind做k8s安装，也可以使用kubeadm** **docker内置安装https://codechina.csdn.net/mirrors/AliyunContainerService/k8s-for-docker-desktop/-/tree/v1.21.3
个人推荐docker内置安装，避免翻墙
简单使用（后期补充，都是新手教程） 元数据 发布一个应用 修改一个应用 挂载目录 进入容器 删除一个应用 执行一个job kubectl apply -f xxxxx （任务已存在不可重复执行，需要先delete） 强制重启kubectl replace –force -f xxxxx Pod Pod，其实是一组共享了某些资源的容器， pod里的所有容器，共享的是同一个 Network Namespace，并且可以声明共享同一个 Volume。
为什么需要pod pod和容器之间的关系 使用pod的优点 pod的基础使用 如何理解一切属性、namespace的操作都是pod级别的 相关操作 共享进程（pid namespace） Lifecycle 容器的hook pod对象在k8s中的声明周期 pod的状态
pod 进阶操作 Volume 投射数据卷 用来为容器促提供预制好的数据的，比如配置等 常见的Projected Volume一共有四种
Secret ConfigMap Downward API ServiceAccountToken 健康检查和恢复机制 PodPreset Pod预设值功能（很实用） 控制器模型 控制器定义 被控制对象 和实践驱动的区别和练习 副本和扩展 Deployment 控制器实际操纵的，正是这样的 ReplicaSet （副本集）对象，而不是 Pod 对象。
对于一个 Deployment 所管理的 Pod，它的 ownerReference 是ReplicaSet
一个 ReplicaSet 对象，其实就是由副本数目的定义和一个 Pod 模板组成的。
可以通过kubectl get rs 查看
滚动发布 扩展 回滚 回滚指定版本 金丝雀发布
深入理解StatefulSet（一）：拓扑状态 两种状态
拓扑状态：多个应用按照顺序启动，有依赖关系 存储状态：应用的多个实例分别绑定了不同的存储数据 StatefulSet 的核心功能，就是通过某种方式记录这些状态，然后在 Pod 被重新创建时，能够为新 Pod 恢复这些状态。
service如何被访问：
service vip模式：虚拟ip，通过直接访问虚拟ip时，直接转发该service代理的某个pod上 以service的DNS方式：访问service会访问到其代理的DNS记录， 就可以访问到service所代理的pod StatefulSet 这个控制器的主要作用之一，就是使用 Pod 模板创建 Pod 的时候，对它们进行编号，并且按照编号顺序逐一完成创建工作。而当 StatefulSet 的“控制循环”发现 Pod 的“实际状态”与“期望状态”不一致，需要新建或者删除 Pod 进行“调谐”的时候，它会严格按照这些 Pod 编号的顺序，逐一完成这些操作。
所以，StatefulSet 其实可以认为是对 Deployment 的改良。
与此同时，通过 Headless Service 的方式，StatefulSet 为每个 Pod 创建了一个固定并且稳定的 DNS 记录，来作为它的访问入口。
实际上，在部署“有状态应用”的时候，应用的每个实例拥有唯一并且稳定的“网络标识”，是一个非常重要的假设。
深入理解StatefulSet（二）：存储状态 Volume之PVC（Persistent Volume Claim）
简单来说就是使用PV申明一个类似分布式存储的PersistentVolume pod服务，提供PVC给pod调用
PVC 其实就是一种特殊的 Volume。只不过一个 PVC 具体是什么类型的 Volume，要在跟某个 PV 绑定之后才知道。
首先，StatefulSet 的控制器直接管理的是 Pod。这是因为，StatefulSet 里的不同 Pod 实例，不再像 ReplicaSet 中那样都是完全一样的，而是有了细微区别的。比如，每个 Pod 的 hostname、名字等都是不同的、携带了编号的。而 StatefulSet 区分这些实例的方式，就是通过在 Pod 的名字里加上事先约定好的编号。
其次，Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录。只要 StatefulSet 能够保证这些 Pod 名字里的编号不变，那么 Service 里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变，而这条记录解析出来的 Pod 的 IP 地址，则会随着后端 Pod 的删除和再创建而自动更新。这当然是 Service 机制本身的能力，不需要 StatefulSet 操心。
最后，StatefulSet 还为每一个 Pod 分配并创建一个同样编号的 PVC。这样，Kubernetes 就可以通过 Persistent Volume 机制为这个 PVC 绑定上对应的 PV，从而保证了每一个 Pod 都拥有一个独立的 Volume。
在这种情况下，即使 Pod 被删除，它所对应的 PVC 和 PV 依然会保留下来。所以当这个 Pod 被重新创建出来之后，Kubernetes 会为它找到同样编号的 PVC，挂载这个 PVC 对应的 Volume，从而获取到以前保存在 Volume 里的数据。
从这些讲述中，我们不难看出 StatefulSet 的设计思想：StatefulSet 其实就是一种特殊的 Deployment，而其独特之处在于，它的每个 Pod 都被编号了。而且，这个编号会体现在 Pod 的名字和 hostname 等标识信息上，这不仅代表了 Pod 的创建顺序，也是 Pod 的重要网络标识（即：在整个集群里唯一的、可被的访问身份）。
有了这个编号后，StatefulSet 就使用 Kubernetes 里的两个标准功能：Headless Service 和 PV/PVC，实现了对 Pod 的拓扑状态和存储状态的维护。
实际上，在下一篇文章的“有状态应用”实践环节，以及后续的讲解中，你就会逐渐意识到，StatefulSet 可以说是 Kubernetes 中作业编排的“集大成者”。
因为，几乎每一种 Kubernetes 的编排功能，都可以在编写 StatefulSet 的 YAML 文件时被用到。
深入理解StatefulSet（三）：有状态应用实践 搭建一主多从的mysql服务
容器化守护进程的意义：DaemonSet DaemonSet特征：
每个节点****必有且只有一个这样的pod实例 当有新的节点加入集群，该pod就会自动的再新节点上被创建 使用场景：
日志上报 节点监控 k8s网络基础服务 每个节点上有且只有一个 Pod的保证基础： nodeAffinity Toleration
撬动离线业务：Job与CronJob 重启策略：restartPolicy 重启次数：backoffLimit 运行最大时间：activeDeadlineSeconds
job controller并行作业 parallelism：定义一个job在任意时间最多可以启动多少个pod completions：定义的是job至少要完成的pod数量，即job最小完成数
三种常用的job用法 最简单粗暴的用法：外部管理器 +Job 模板。（参考KubeFlow） 拥有固定任务数目的并行 Job 指定并行度（parallelism），但不设置固定的 completions 的值。 cronjob job重复策略 concurrencyPolicy=Allow，这也是默认情况，这意味着这些 Job 可以同时存在 concurrencyPolicy=Forbid，这意味着不会创建新的 Pod，该创建周期被跳过 concurrencyPolicy=Replace，这意味着新产生的 Job 会替换旧的、没有执行完的 Job 而如果某一次 Job 创建失败，这次创建就会被标记为“miss”。当在指定的时间窗口内，miss 的数目达到 100 时，那么 CronJob 会停止再创建这个 Job
声明式API与Kubernetes编程范式 kubectl create，再 replace 的操作，我们称为命令式配置文件操作，替换原有的api对象
kubectl apply 声明式 API：是对原有的api对象操作
指的就是我只需要提交一个定义好的 API 对象来“声明”，我所期望的状态是什么样子。 “声明式 API”允许有多个 API 写端，以 PATCH 的方式对 API 对象进行修改，而无需关心本地原始 YAML 文件的内容。 最后，也是最重要的，有了上述两个能力，Kubernetes 项目才可以基于对 API 对象的增、删、改、查，在完全无需外界干预的情况下，完成对“实际状态”和“期望状态”的调谐（Reconcile）过程。 声明式 API，才是 Kubernetes 项目编排能力“赖以生存”的核心所在
声明式api的好处，是不会重复生成对象，因为很多情况下都需要初始化处理
深入解析声明式API（一）：API对象的奥秘 有点难
深入解析声明式API（二）：编写自定义控制器 后期使用
RBAC 角色权限控制 偏于运维，过
聪明的微创新：Operator工作原理解读 后面在学吧
官方介绍 operatorframework官方文档 如何从零开始编写一个Kubernetes CRD Kubernetes Operator 快速入门教程 知乎：十分钟弄懂 k8s Operator 应用的制作流程 云海天：Operator K8S – 光速理解operator 如何在kubernetes中开发自己的Operator 书栈网：KubeOperator v2.0 使用教程 Kubernetes Operator最佳实践
存储卷：PV、PVC、StorageClass，FlexVolume与CSI PV：是持久化存储的数据卷。是定义的一个持久化存储在宿主机上的目录，描述。 PVC：Pod所希望使用的持久化存储的属性。比如Volume存储的大小，权限等。
用go举个例子：PV就是一个对象具体实现了一个方法；pvc就是通过接口签名调用了pv这个方法。
这样做的好处是，作为应用开发者，我们只需要跟 PVC 这个“接口”打交道，而不必关心具体的实现是 NFS 还是 Ceph。毕竟这些存储相关的知识太专业了，应该交给专业的人去做。
CSI插件编写等
容器网络 Linux 容器能看见的“网络栈”，实际上是被隔离在它自己的 Network Namespace 当中的。
网络栈：网卡（Network Interface）、回环设备（Loopback Device）、路由表（Routing Table）和 iptables 规则。
在大多数情况下，我们都希望容器进程能使用自己 Network Namespace 里的网络栈，即：拥有属于自己的 IP 地址和端口。
这个被隔离的容器进程，该如何跟其他 Network Namespace 里的容器进程进行交互呢？
在 Linux 中，能够起到虚拟交换机作用的网络设备，是网桥（Bridge）。它是一个工作在数据链路层（Data Link）的设备，主要功能是根据 MAC 地址学习来将数据包转发到网桥的不同端口（Port）上。
当然，至于为什么这些主机之间需要 MAC 地址才能进行通信，这就是网络分层模型的基础知识了。不熟悉这块内容的读者，可以通过这篇文章来学习一下。
为了实现上述目的，Docker 项目会默认在宿主机上创建一个名叫 docker0 的网桥，凡是连接在 docker0 网桥上的容器，就可以通过它来进行通信。
可是，我们又该如何把这些容器“连接”到 docker0 网桥上呢？
这时候，我们就需要使用一种名叫Veth Pair的虚拟设备了。
Veth Pair 设备的特点是：它被创建出来后，总是以两张虚拟网卡（Veth Peer）的形式成对出现的。并且，从其中一个“网卡”发出的数据包，可以直接出现在与它对应的另一张“网卡”上，哪怕这两个“网卡”在不同的 Network Namespace 里。
这就使得 Veth Pair 常常被用作连接不同 Network Namespace 的“网线”。
深入解析容器跨主机网络 理解容器“跨主通信”的原理，就一定要先从 Flannel 这个项目说起。
Flannel 项目是 CoreOS 公司主推的容器网络方案。事实上，Flannel 项目本身只是一个框架，真正为我们提供容器网络功能的，是 Flannel 的后端实现。目前，Flannel 支持三种后端实现，分别是：
VXLAN host-gw UDP 这三种不同的后端实现，正代表了三种容器跨主网络的主流实现方法。
CNI 网络插件
Fannel host-gw 模式和 Calico 这两种纯三层网络方案
NetworkPolicy：设置流量白名单
找到容器不容易：Service、DNS与服务发现 Service 是由 kube-proxy 组件，加上 iptables 来共同实现的。
kubeproxy通过组件感知到service对象添加，会在iptables上添加规则（该规则就是为service设置一个固定的入口地址）：目的地址是xxxx，端口是xx的ip包都跳转到另一条iptables链路中处理，这条链路是一组规则的集合，其实也就是代理的pod的最终地址。
问题：一直以来，基于 iptables 的 Service 实现，都是制约 Kubernetes 项目承载更多量级的 Pod 的主要障碍。
而 IPVS 模式的 Service，就是解决这个问题的一个行之有效的方法。
IPVS 模式的工作原理，其实跟 iptables 模式类似。当我们创建了前面的 Service 之后，kube-proxy 首先会在宿主机上创建一个虚拟网卡（叫作：kube-ipvs0），并为它分配 Service VIP 作为 IP 地址。
接下来，kube-proxy 就会通过 Linux 的 IPVS 模块，为这个 IP 地址设置三个 IPVS 虚拟主机，并设置这三个虚拟主机之间使用轮询模式 (rr) 来作为负载均衡策略。我们可以通过 ipvsadm 查看到这个设置。
相比于 iptables，IPVS 在内核中的实现其实也是基于 Netfilter 的 NAT 模式，所以在转发这一层上，理论上 IPVS 并没有显著的性能提升。但是，IPVS 并不需要在宿主机上为每个 Pod 设置 iptables 规则，而是把对这些“规则”的处理放到了内核态，从而极大地降低了维护这些规则的代价。这也正印证了我在前面提到过的，“将重要操作放入内核态”是提高性能的重要手段。
所以，在大规模集群里，我非常建议你为 kube-proxy 设置–proxy-mode=ipvs 来开启这个功能。它为 Kubernetes 集群规模带来的提升，还是非常巨大的。
总结：** **ClusterIP 模式的 Service 为你提供的，就是一个 Pod 的稳定的 IP 地址，即 VIP。并且，这里 Pod 和 Service 的关系是可以通过 Label 确定的。
而 Headless Service 为你提供的，则是一个 Pod 的稳定的 DNS 名字，并且，这个名字是可以通过 Pod 名字和 Service 名字拼接出来的。
从外界连通Service的方式” 如何从外部（Kubernetes 集群之外），访问到 Kubernetes 里创建的 Service？
NodePort LoadBalancer ExternalName ingrss NodePort注意点：一台宿主机上的 iptables 规则，会设置为只将 IP 包转发给运行在这台宿主机上的 Pod。当然，这也就意味着如果在一台宿主机上，没有任何一个被代理的 Pod 存在，比如上图中的 node 2，那么你使用 node 2 的 IP 地址访问这个 Service，就是无效的。此时，你的请求会直接被 DROP 掉。
LoadBalancer：适用于公有云上的 Kubernetes 服务，使用了一个叫作 CloudProvider 的转接层，来跟公有云本身的 API 进行对接。所以，在上述 LoadBalancer 类型的 Service 被提交后，Kubernetes 就会调用 CloudProvider 在公有云上为你创建一个负载均衡服务，并且把被代理的 Pod 的 IP 地址配置给负载均衡服务做后端。
Ingress：全局的、为了代理不同后端 Service 而设置的负载均衡服务；其实就是 Kubernetes 项目对“反向代理”的一种抽象。可以根据 Ingress 对象和被代理后端 Service 的变化，来自动进行更新的负载均衡器。
目前，Ingress 只能工作在七层，而 Service 只能工作在四层。所以当你想要在 Kubernetes 里为应用进行 TLS 配置等 HTTP 相关的操作时，都必须通过 Ingress 来进行。
k8s资源模型与资源管理 在 Kubernetes 中，像 CPU 这样的资源被称作“可压缩资源”（compressible resources）。它的典型特点是，当可压缩资源不足时，Pod 只会“饥饿”，但不会退出。
而像内存这样的资源，则被称作“不可压缩资源（incompressible resources）。当不可压缩资源不足时，Pod 就会因为 OOM（Out-Of-Memory）被内核杀掉。
而由于 Pod 可以由多个 Container 组成，所以 CPU 和内存资源的限额，是要配置在每个 Container 的定义上的。这样，Pod 整体的资源配置，就由这些 Container 的配置值累加得到。
其中，Kubernetes 里为 CPU 设置的单位是“CPU 的个数”。比如，cpu=1 指的就是，这个 Pod 的 CPU 限额是 1 个 CPU。当然，具体“1 个 CPU”在宿主机上如何解释，是 1 个 CPU 核心，还是 1 个 vCPU，还是 1 个 CPU 的超线程（Hyperthread），完全取决于宿主机的 CPU 实现方式。Kubernetes 只负责保证 Pod 能够使用到“1 个 CPU”的计算能力。
此外，Kubernetes 允许你将 CPU 限额设置为分数，比如在我们的例子里，CPU limits 的值就是 500m。所谓 500m，指的就是 500 millicpu，也就是 0.5 个 CPU 的意思。这样，这个 Pod 就会被分配到 1 个 CPU 一半的计算能力。
你也可以直接把这个配置写成 cpu=0.5。但在实际使用时，我还是推荐你使用 500m 的写法，毕竟这才是 Kubernetes 内部通用的 CPU 表示方式。
而对于内存资源来说，它的单位自然就是 bytes。Kubernetes 支持你使用 Ei、Pi、Ti、Gi、Mi、Ki（或者 E、P、T、G、M、K）的方式来作为 bytes 的值。比如，在我们的例子里，Memory requests 的值就是 64MiB (2 的 26 次方 bytes) 。这里要注意区分 MiB（mebibyte）和 MB（megabyte）的区别。
备注：1Mi=10241024；1M=10001000
，Kubernetes 里 Pod 的 CPU 和内存资源，实际上还要分为 limits 和 requests 两种情况
k8s默认资源调度器 k8s容器运行时 sig-Node CRI k8s容器监控和日志 监控数据分类 按照 Metrics 数据的来源，来对 Kubernetes 的监控体系分类
宿主机的监控数据 Kubernetes 的 API Server、kubelet 等组件的 /metrics API Kubernetes 相关的监控数据，包括 Pod、Node、容器、Service 等主要 Kubernetes 核心概念的 Metrics 其中，容器相关的 Metrics 主要来自于 kubelet 内置的 cAdvisor 服务。在 kubelet 启动后，cAdvisor 服务也随之启动，而它能够提供的信息，可以细化到每一个容器的 CPU 、文件系统、内存、网络等资源的使用情况。
Custom Metrics 容器日志收集与管理 方案：
Node上部署logging agent，将日志文件转发到后端存储里保存。 不难看到，这里的核心就在于 logging agent ，它一般都会以 DaemonSet 的方式运行在节点上，然后将宿主机上的容器日志目录挂载进去，最后由 logging-agent 把日志转发出去。
举个例子，我们可以通过 Fluentd 项目作为宿主机上的 logging-agent，然后把日志转发到远端的 ElasticSearch 里保存起来供将来进行检索。具体的操作过程，你可以通过阅读这篇文档来了解。另外，在很多 Kubernetes 的部署里，会自动为你启用 logrotate，在日志文件超过 10MB 的时候自动对日志文件进行 rotate 操作。
可以看到，在 Node 上部署 logging agent 最大的优点，在于一个节点只需要部署一个 agent，并且不会对应用和 Pod 有任何侵入性。所以，这个方案，在社区里是最常用的一种。
但是也不难看到，这种方案的不足之处就在于，它要求应用输出的日志，都必须是直接输出到容器的 stdout 和 stderr 里。
针对1的不足，当容器的日志只能输出到某些文件里的时候，我们可以通过一个 sidecar 容器把这些日志文件重新输出到 sidecar 的 stdout 和 stderr 上，这样就能够继续使用第一种方案了 就是通过一个 sidecar 容器，直接把应用的日志文件发送到远程存储里面去。也就是相当于把方案一里的 logging agent，放在了应用 Pod 里。 在这种方案里，你的应用还可以直接把日志输出到固定的文件里而不是 stdout，你的 logging-agent 还可以使用 fluentd，后端存储还可以是 ElasticSearch。只不过， fluentd 的输入源，变成了应用的日志文件。一般来说，我们会把 fluentd 的输入源配置保存在一个 ConfigMap 里
总结： 建议将应用日志输出到 stdout 和 stderr，然后通过在宿主机上部署 logging-agent 的方式来集中处理日志。
这种方案不仅管理简单，kubectl logs 也可以用，而且可靠性高，并且宿主机本身，很可能就自带了 rsyslogd 等非常成熟的日志收集组件来供你使用。
除此之外，还有一种方式就是在编写应用的时候，就直接指定好日志的存储后端</content></entry><entry><title>容器学习笔记</title><url>/post/docker_learn_note/</url><categories><category>学习</category></categories><tags><tag>技术</tag><tag>容器</tag><tag>docker</tag></tags><content type="html"> 容器技术 行为算法的区别（容器cpu和宿主机cpu占用率计算方式区别） 隔离程度：cpu，memory，IO 处理性能敏感的应用，需要做cgroup，网络优化等两个重点： Namespace和Cgroups Namespace和Cgroups对Linux原来模块的影响 Namespaces linux创建容器的时候，就会建出PID Namespace，在这个pid namespace中只能看到namespace中的进程，而且看不到其他的namespace里的进程
所以namespace其实就是一个隔离机制，主要目的是隔离运行在同一个宿主机上的容器，让这些容器不能彼此访问彼此的资源
作用：
充分利用系统的资源，也即是同一个宿主机可以运行多个用户的容器 保证安全性，同一个用户之间不嫩个访问对方的资源 除了pid namespace（进程隔离）还有network namespace（网络隔离），mount namespace（文件隔离）统称资源隔离。
其实还有：user(用户和用户组)、uts（主机名与域名），ipc（信号量、消息队列和共享内存）隔离
Cgroups 对计算机资源的限制，比如cpu的限制，内存的使用量，IO设备的流量。
通过不同的子系统限制不同资源
常用的Cgroups子系统：
CPU子系统，用来限制一个控制组（可理解为一个容器内所有进程）可使用的最大CPU memory子系统，限制控制组最大的内存使用量 pids子系统，用来限制一个控制组最多可以运行多少进程 cpuset子系统：限制控制组的进行可以在几个物理cpu上运行 进程信号处理 忽略 对信号不做任何处理
捕获 用户进程自己注册信号handler
缺省 Linux为每个信号都定义了一个缺省的行为，对大部分的信号，用户不需要自己注册handler，使用系统的缺省定义行为即可
注意： kill和stop除外，因为这是内核和超级用户删除任何进程的特权，只能有执行系统处理，用户不能单独处理
重点信号 SIGTERM 这个信号是kill缺省发出的。可以由用户注册handler去捕获
SIGKILL 这个是特权信号，杀死进程
最终可有确定两个
在容器中是不工作的，内核阻止了 1 号进程对 SIGKILL 特权信号的响应。 kill 分两种情况，如果 1 号进程没有注册 SIGTERM 的 handler，那么对 SIGTERM 信号也不响应，如果注册了 handler，那么就可以响应 SIGTERM 信号。 3. 在容器中，1号进程永远不会响应SIGKILL和SIGSTOP这两个特权信号。 为什么要防止僵尸进程 限制cgroup的进程数量限制，一旦超过进程数量，那么正常进程无法正常启动，且僵尸进程无法被杀死
为什么容器中的进程被杀死了 1当docker停止一个容器的时候，containerd服务会向容器的init进程发送一个SIGTERM信号，没有相应即30s之后给当前进程发送SIGKILL，当前进程关闭后给子进程发送SIGKILL。但是SIGKILL是不能捕获的
linux命令：strace -p pid
如何限制cpu 关注top下的Cpu
$ top %Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si us: 用户程序代码 sy: 系统调用，比如读取文件的系统调用过程 wa: io等待时间，读取文件时交给了总线DMA操作 id： 空闲状态 hi：cpu硬中断时间 si：software interrupt软件中断，软中断 ni：nice，nice值1-19的进程用户态cpu时间 st：steal，表示同一个宿主机上的其他虚拟机抢走的cpu时间
cpu的cgroup一般限制的是us和ni，还有一部分内核态sy
cpu cgroups限制参数 cpu的Cgroups有三个参数
cpu.cfs_quota_us：cfs算法的一个调度周期，一般值为100000，也就是100ms cpu.cfs_period_us：cfs算法中在一个调度周期里这个控制组被允许允许时间，比如值是50000，就是50ms cpu.shares：控制组之间的cpu分配比例，缺省值1024 如何正确的获取容器cpu开销 首先，在容器中的top中的cpu是反应的宿主机的cpu情况 。。。。。
为什么容器很慢 继续top load average: 系统中可运行队列中进程数量+休眠队列中不可打断的进程平均数 如果load average值升高，且应用性能下降，真正的原因是什么？ ps aux | grep &ldquo;D&rdquo; 这样子可以找到有哪些进程休眠且不可被打断了。 D状态主要是因为disk i/o的党文和信号量的锁党文，因此,D状态在linux中很常见，这是一种对资源的竞争。
D状态引起的容器性能下降问题是CGroup无法解决的，因为资源的竞争是全局的
容器为什么被kill掉的 原因：容器中的进程使用了太多的内存，超过了memory cgroup的内存限制，linux就会主动杀死容器内的进程，可能造成整个容器退出 命令：查看容器退出原因 docker inspect 容器id | grep -i Status -A 10
memory Cgroups 和cpu的 cgroups一样有三个参数
memory.limit_in_bytes：限制控制组中所有进程可使用的内存最大值 memory.oom_control：当limit_in_bytes满足时触发的行为，默认OOM Killer memory_usage_in_bytes：当前控制组中所有进程实际使用的内存总和 如何确定容器发生了OOM，可以通过内核日志及时发现
使用journal -k 查看/var/log/message 为什么容量总是在使用临界点 涉及到用户态相关的两个内存类型：RSS和Page Cache
RSS：进程真正申请到物理页面的内存大小，因为malloc分配的内存是虚拟地址，但没有被使用，其RSS为0，只有使用了才会有物理页面，而且实际使用多少，RSS就是多少。 Page Cache：进程对文件读写操作时，系统会分配内存将磁盘上读写到的页面放到内存中的数据。 如果系统中有空闲的内存，系统就会自动把读写过的磁盘文件放到page cache中，如果内存不够了，就会进行内存管理机制进行内存回收。 PageCache只是启动缓存作用，因此会被优先回收释放
linux命令：查看具体的内存使用量：cat memory.stat
容器可以使用Swap空间吗？ 本质上是可以使用swap空间的 但是内存泄露的进程没有被杀死，还会不断的读写swap磁盘，影响了整个节点的性能。 最终就是一个平衡点的，参考功能原理：swappiness swappiness取值范围： 100：脂肪page cache和匿名内存是同等优先级 60：默认值，page cache的释放优先级高于匿名内存的释放 0：当系统中内存低于临界值时，仍然会释放匿名内存并把页面写写入到swap空间
在容器中读写文件变慢了 容器文件系统的不支持 容器文件系统 Linux命令：pref
减少相同镜像文件在同一个节点的数据冗余们可以节省磁盘空间，也可以减少镜像文件下载的网络资源 UnionFS作为容器文件系统，是通过多个目录挂在的方式工作 OverlayFS是UnionFS的一种实现，是目前主流Linux版本中的使用的容器文件系统 OverlayFS是吧多个目录合并挂载，被挂载的目录分为两大类：lowerdir和upperdir lowerdir允许有多个目录，被挂载之后这些文件是不会被删除和修改的，也就是只读 upperdir只有一个，是可读写的，挂载点的目录中所有的文件修改都会在upperdir中反应 容器文件Quota：容器为什么把宿主机的磁盘写满了 容器写入的文件都是直接写入到宿主机上的，因此有可能让把宿主机写满
那如何都写入做限流呢？
linux都是使用的xfs和ext4文件系统 使用Quota进行对一个用户，一个用户组，或者一个项目限制他们使用文件系统的额度（quota） 具体方案 4. 给目标目录打赏一个Project ID 5. 给这个Project ID在XFS文件系统中设置一个写入数据块的限制 Docker就是使用了这个方法，用XFS Quote来限制OverlayFS的upperdir目标，通过这个方式控制同期OverlayFS根目录大小
容器里磁盘读写不稳定 具体来说就是多个容器同时读写节点上的同一块磁盘，那么他们的磁盘读写相互之间的影响如何解决。 Linux命令： fio
通过fio命令进行测试，发现多个同期同时写一块磁盘的时候，它的性能受到了干扰。
之前，我们用Cgroups来保证容器的CPU使用率，以及控制memory的可用大小，我们是不是也可以通过Cgroups来保证容器的磁盘读写性能？
在Cgroups v1中有一个blkio子系统，用来限制磁盘IO的
磁盘两个常见指标
IOPS：每秒钟磁盘读写次数 throughput：每秒钟磁盘数据吞吐量也可以成为带宽 两者关系是：吞吐量=数据块大小 * IOPS 在blkio Cgroups中有四个主要的参数，用来限制磁盘的io性能
blkio.throttle.read_iops_device blkio.throrrle.read_bps_device // 吞吐量 blkio.throttle.write_iops_device blkio.throrrle.write_bps_device 但是该模式是Linux系统下的Direct IO模式
Linux有两者文件IO模式：Direct IO和Buffered IO。
DirectIO：文件系统层->块设备层->磁盘驱动->磁盘硬件写入 BufferedIO: 用户进程吧文件数据写入到内存中就返回了，Linux自由的线程会通过DMA模式，写入到磁盘中
DirectIO可以用通过blkio限制磁盘IO，但是bufferedIO不能被限制
如何限制bufferedIO呢？ 这就需要Cgroups v2了
第一步打开Cgroups v2的功能，因为限制及时最新的linux系统也是默认关闭的 在进行设（百）置（度） 容器中的内存与I/O：容器写文件的延时为什么波动很大？ 在Linux默认系统调用下，buffered io是默认模式，使用方便
但是在容器中使用的话，发现多了memory cgroup限制之后，write写相同大小的数据块花费的的时间，延时波动比较大
这是为什么呢？ Linux命令：perf和ftrace
由于这是 Buffered I/O 方式，对于写入文件会先写到内存里，这样就产生了 dirty pages，所以我们先研究了一下 Linux 对 dirty pages 的回收机制是否会影响到容器中写入数据的波动。
在这里我们最主要的是理解这两个参数，dirty_background_ratio 和 dirty_ratio，这两个值都是相对于节点可用内存的百分比值。
当 dirty pages 数量超过 dirty_background_ratio 对应的内存量的时候，内核 flush 线程就会开始把 dirty pages 写入磁盘 ; 当 dirty pages 数量超过 dirty_ratio 对应的内存量，这时候程序写文件的函数调用 write() 就会被阻塞住，直到这次调用的 dirty pages全部写入到磁盘。
在节点是大内存容量，并且 dirty_ratio 为系统缺省值 20%，dirty_background_ratio 是系统缺省值 10% 的情况下，我们通过观察 /proc/vmstat 中的 nr_dirty 数值可以发现，dirty pages 不会阻塞进程的 Buffered I/O 写文件操作。 所以我们做了另一种尝试，使用 perf 和 ftrace 工具对容器中的写文件进程进行 profile。我们用 perf 得到了系统调用 write() 在内核中的一系列子函数调用，再用 ftrace 来查看这些子函数的调用时间。
根据 ftrace 的结果，我们发现写数据到 Page Cache 的时候，需要不断地去释放原有的页面，这个时间开销是最大的。造成容器中 Buffered I/O write() 不稳定的原因，正是容器在限制内存之后，Page Cache 的数量较小并且不断申请释放。
其实这个问题也提醒了我们：在对容器做 Memory Cgroup 限制内存大小的时候，不仅要考虑容器中进程实际使用的内存量，还要考虑容器中程序 I/O 的量，合理预留足够的内存作为 Buffered I/O 的 Page Cache。
比如，如果知道需要反复读写文件的大小，并且在内存足够的情况下，那么 MemoryCgroup 的内存限制可以超过这个文件的大小。
还有一个解决思路是，我们在程序中自己管理文件的 cache 并且调用 Direct I/O 来读写文件，这样才会对应用程序的性能有一个更好的预期。
网络 容器网络 Network Namespace可以隔离网络设备，ip协议栈，ip路由表，防火墙规则等，以及可以显示独立的网络状态信息
我们可以通过clone()或者unshare()系统调用来简历新的network namespace。
此外，还有一些工具“ip netns”，“unshare”，“lsns”和“nsenter”也可以操作。 如何修改容器中的网络参数 由于安全原因，普通容器的/proc/sys/是简历在容器文件系统底层的，是read-only mount的，所以在容器启动以后，我们无法在容器内部修改/proc/sys/net下的网络相关的参数。
如果需要修改，需要通过runC sysctl相关的接口，在容器启动的时候对容器内部的网络参数做配置。
docker：加上&ndash;sysctl参数
k8s：需要allowed unsafe sysctl特性
如何配置容器网络接口 且如何在容器不通的时候，如何简单测试
思考下让容器中的数据包最终发送到物理网卡上，需要哪些步骤
数据包从容器的network namespace发送到host network namespace上 数据发到host network namespace之后，还要解决数据包怎么从宿主机上eth0发送出去的问题 先解决第一步从容器到宿主机的network namespace有哪些方式呢？
veth macvlan/ipvlan 在docker启动的容器缺省的默认网络接口模式是veth
veth是一个虚拟的网络设备，一般都是成对创建的，而且这对设备是相互连接的，当每个设备在不同的network namespaces的时候，namespace之间就可以用这对veth进行网络通讯了。
使用veth进行容器网络发送到宿主机网络了，之后怎么从宿主机eth0发送出去？
解决方法：
nat转发 overlay网络发送 proxy arp+路由方式 docker默认使用bridge+nat转发
重点是，如果网络不通，使用tcpdump找到具体哪一步数据包停止了转发？ Linux命令：tcpdump
如何优化容器网络时延问题 veth网络接口从配置上看，一个数据包要从容器里发送到宿主机外，需要先从容器里的eth0把包发送到宿主机的veth_host，然后再从宿主机上通过nat或者路由的方式，经过宿主机的eth0向外发送。
这种容器向外发送数据包的路径，相比宿主机直接向外发送数据包的路径，明显多了一次接口层的发送和接收，增加开销
如果程序对网络性能有很高要求，如何解决呢？
可以使用netperf模拟测试下网络迟延问题
Linux命令：netperf
可以换成其他网络噢诶之模式，比如macvlan或者ipvlan
原理：在物理的网络接口上配置几个虚拟的网路接口，配置独立的ip，这些ip可以属于不同的namespace。
不同点：macvlan有独立的mac地址，而ipvlan是所有共享一个mac地址
缺点：由于ipvlan/macvlan网络接口直接挂在物理网络接口上，对于需要使用iptables规则的容器，比如k8s使用service服务的容器就不能工作了。
乱序重传问题 veth接口会不会引起乱序重传？原因是什么？如何解决？ Linux命令：iperf3
数据包重传可能原因：
数据包网络中丢了 数据包乱序 使用tcpdump抓包量比较大，额外系统开销也比较大 可以使用netstat进行查看协议栈中丢包和重传的情况 可以看到 fast retransmits （快速回传）
快速回传：如果发送端收到3个重复的ack，那么发送端就可以立刻重新发送ack对应的下一个数据包，而不用等待发送超时。
通过对veth网络接口研究，我们知道他可能增加数据包乱序的几率。
RPS和RSS作用类似，都是把数据包分散到更多的CPU上进行处理，使得系统有更强的网络报处理能力。他们的区别是RSS工作在网卡的硬件层，而RPS工作在Linux内核的软件层。
在把数据包分散到各个cpu时，RPS保证了同一个数据流是在同一个CPU上的，这样就可以有效减少包的乱序。那么我们可以把RPS的这个特性配置到veth网络接口上，来减少数据包乱序的几率
但是RPS配置还是会带来额外的系统开销，在某些网络环境中会引起softriq CPU使用率的增加大。是否开启需要根据场景进行评估。
同时tcp的乱序包也不一样会产生数据包的回传。想要减少网络包的回传也可以参考协议栈的其他参数设置，如/proc/sys/net/ipv4/tcp_reordering。
另外使用http2.0可以有效减少回传。
容器安全 运行容器的时候，在安全方面可以做哪些？
赋予容器合理的capabilities 在容器中以非root用户运行程序 使用系统命令但没有权限，即时以root？为什么？因为执行需要capabilities，只要在启动的时候，需要加上privileged参数
Linux capabilities Linux命令：capsh capabilities：简单来说对应任意一个进程，在做任意一个特权操作的时候，都需要有这个特权操作对应的capability。就是吧linux root用户原来所有的特权做了细化，可以更加细粒度的给进程赋予不同的权限。
但是也不能直接给容器直接设置成privileged，也就是把所有capability都赋予容器，否则容器就可以直接修改宿主机上的所有文件了。
可以按需给与，比如需要iptables，可以设置 &ndash;cap-add NET_ADMIN就可以了
root模式 尽管容器中的root用户的linux capabilities已经减少很多，但是在没有没有User Namespace的情况下，容器中的root用户和宿主机上的root用户的uid是完全相同的，一旦有软件的漏洞，容器中的root用户就可以操作整个宿主机。
为了减少安全风险，业界都见识在容器中以非root用户来运行进程，不过在没有 USer Namespace的情况下，容器中使用给root用户，对容器云平台来说，对uid的管理会比较麻烦。
所以，我们分析下User Namespace，它带来的好处有两个。一个是吧容器中的root用户映射成宿主机上的普通用户，另外一个好处是在云平台里对容器的uid分配较为容易。
除了在容器中以非root用户来运行进程外，docker和podman都已经支持rootless container，进一步降低了容器的安全风险。
学习自：极客时间-容器实战高手 待补充实战课</content></entry><entry><title>关于我</title><url>/about.html</url><categories/><tags/><content type="html"> 感谢凡梦星尘的主题分析 感谢Hugo的静态站点生成器</content></entry></search>